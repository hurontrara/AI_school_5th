{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m0y2719ZVbw9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6336,
     "status": "ok",
     "timestamp": 1653283039757,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "m0y2719ZVbw9",
    "outputId": "5aa7f337-6ffd-4309-bc57-4652641575ea"
   },
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CjDG6U4GWRSo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6267,
     "status": "ok",
     "timestamp": 1653300351120,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "CjDG6U4GWRSo",
    "outputId": "0954502f-8994-4116-ccf0-b074298de33c"
   },
   "outputs": [],
   "source": [
    "# !pip install -U finance-datareader\n",
    "# !pip install pykrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# with tf.device(\"/GPU:0\"):\n",
    "#     for i in range(10):\n",
    "#         a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "#         b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "#         c = tf.matmul(a, b)\n",
    "\n",
    "#     print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a007f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48f2713",
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1653305905503,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "d48f2713"
   },
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn import ensemble\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c91bb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime, os\n",
    "from PIL import Image\n",
    "from tensorflow.python.client import device_lib\n",
    "from mplfinance.original_flavor import candlestick2_ohlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396112bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torchvision.transforms as T\n",
    "from pykrx import stock\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f6f395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac84c557",
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1653305501740,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "ac84c557"
   },
   "outputs": [],
   "source": [
    "def draw_pictures(data, days):\n",
    "    \n",
    "    global data_5\n",
    "    global variable\n",
    "        \n",
    "    for i in range(days, len(data) + 1, 20):\n",
    "        \n",
    "        variable += 1\n",
    "\n",
    "        local_data = data.iloc[i - days : i]\n",
    "        \n",
    "        if len(local_data) != 20:\n",
    "            continue\n",
    "\n",
    "        label = (data.iloc[i]['Change'] > 0).astype(int)\n",
    "        \n",
    "        fig = plt.figure(figsize=(1, 1), dpi = 300)\n",
    "\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        candlestick2_ohlc(ax, local_data['Open'], local_data['High'], local_data['Low'], local_data['Close'], width=0.5, colorup='r', colordown='b')\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "#         plt.savefig('drive/My Drive/datasets/datasets/{}_{}_{}.png'.format(variables, i, label), dpi = 1000)\n",
    "        if label == 1:\n",
    "            plt.savefig('datasets/1/{}.png'.format(variable))\n",
    "        else:\n",
    "            plt.savefig('datasets/0/{}.png'.format(variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa14a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx import stock\n",
    "\n",
    "stock_code = stock.get_market_ticker_list(date=\"20201020\", market=\"KOSPI\")\n",
    "\n",
    "np.random.shuffle(stock_code)\n",
    "\n",
    "company_list = stock_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9661b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에바야\n",
      "에바야\n",
      "402\n",
      "403\n",
      "에바야\n",
      "에바야\n",
      "406\n",
      "에바야\n",
      "에바야\n",
      "409\n",
      "410\n",
      "에바야\n",
      "412\n",
      "413\n",
      "에바야\n",
      "에바야\n",
      "416\n",
      "에바야\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "426\n",
      "427\n",
      "에바야\n",
      "429\n",
      "에바야\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "에바야\n",
      "442\n",
      "에바야\n",
      "444\n",
      "에바야\n",
      "에바야\n",
      "447\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "452\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "456\n",
      "에바야\n",
      "458\n",
      "459\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "466\n",
      "467\n",
      "468\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "472\n",
      "473\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "478\n",
      "479\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "484\n",
      "485\n",
      "486\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "491\n",
      "492\n",
      "493\n",
      "에바야\n",
      "495\n",
      "496\n",
      "497\n",
      "에바야\n",
      "499\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "503\n",
      "504\n",
      "에바야\n",
      "에바야\n",
      "507\n",
      "에바야\n",
      "에바야\n",
      "510\n",
      "에바야\n",
      "512\n",
      "에바야\n",
      "514\n",
      "에바야\n",
      "에바야\n",
      "=========================================================================================================================\n",
      "518\n",
      "에바야\n",
      "520\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "에바야\n",
      "530\n",
      "에바야\n",
      "에바야\n",
      "533\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "에바야\n",
      "542\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "546\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "에바야\n",
      "557\n",
      "에바야\n",
      "에바야\n",
      "560\n",
      "561\n",
      "562\n",
      "에바야\n",
      "564\n",
      "에바야\n",
      "566\n",
      "567\n",
      "에바야\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "에바야\n",
      "=========================================================================================================================\n",
      "에바야\n",
      "=========================================================================================================================\n",
      "에바야\n",
      "578\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "582\n",
      "에바야\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "에바야\n",
      "591\n",
      "592\n",
      "593\n",
      "에바야\n",
      "에바야\n",
      "596\n",
      "에바야\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "에바야\n",
      "603\n",
      "에바야\n",
      "605\n",
      "에바야\n",
      "607\n",
      "608\n",
      "609\n",
      "에바야\n",
      "611\n",
      "612\n",
      "에바야\n",
      "에바야\n",
      "615\n",
      "에바야\n",
      "617\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "625\n",
      "626\n",
      "에바야\n",
      "628\n",
      "629\n",
      "에바야\n",
      "에바야\n",
      "632\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "636\n",
      "637\n",
      "에바야\n",
      "639\n",
      "640\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "에바야\n",
      "650\n",
      "에바야\n",
      "652\n",
      "에바야\n",
      "654\n",
      "655\n",
      "에바야\n",
      "657\n",
      "658\n",
      "에바야\n",
      "660\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "665\n",
      "에바야\n",
      "=========================================================================================================================\n",
      "에바야\n",
      "669\n",
      "670\n",
      "에바야\n",
      "672\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "677\n",
      "678\n",
      "679\n",
      "에바야\n",
      "681\n",
      "에바야\n",
      "683\n",
      "에바야\n",
      "에바야\n",
      "686\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "698\n",
      "699\n",
      "에바야\n",
      "701\n",
      "에바야\n",
      "에바야\n",
      "704\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "709\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "에바야\n",
      "716\n",
      "717\n",
      "718\n",
      "에바야\n",
      "=========================================================================================================================\n",
      "에바야\n",
      "=========================================================================================================================\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(400, 800):\n",
    "    \n",
    "    try:\n",
    "        code = company_list[i]\n",
    "\n",
    "        if 0 not in list(fdr.DataReader(str(code), '2008', '2022')['Open']):\n",
    "            data = fdr.DataReader(str(code), '2008', '2022')\n",
    "\n",
    "        else:\n",
    "            print('에바야')\n",
    "            continue\n",
    "\n",
    "        data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        draw_pictures(data, 20)\n",
    "\n",
    "        print(i)\n",
    "    except:\n",
    "        print('=========================================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dcdf5ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15798"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "054c0854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 in list(data_5['Open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c5536af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.collections.LineCollection at 0x2354690da00>,\n",
       " <matplotlib.collections.PolyCollection at 0x2354f689250>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(1, 1), dpi = 300)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "candlestick2_ohlc(ax, data_5['Open'], data_5['High'], data_5['Low'], data_5['Close'], width=0.5, colorup='r', colordown='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5440a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59df2eac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_datareader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-ff3664f90454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_datareader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mweb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmpl_finance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_datareader'"
     ]
    }
   ],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_finance\n",
    "\n",
    "start = datetime.datetime(2016, 3, 1)\n",
    "end = datetime.datetime(2016, 3, 31)\n",
    "skhynix = web.DataReader(\"000660.KS\", \"yahoo\", start, end)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "mpl_finance.candlestick2_ohlc(ax, skhynix['Open'], skhynix['High'], skhynix['Low'], skhynix['Close'], width=0.5, colorup='r', colordown='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849563d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42dc04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd103c",
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1653305503925,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "68dd103c"
   },
   "outputs": [],
   "source": [
    "# def make_data_draw_pictures(code, start, end):\n",
    "\n",
    "#     global variables\n",
    "\n",
    "#     variables = code\n",
    "    \n",
    "#     data = fdr.DataReader(code, start, end)\n",
    "    \n",
    "#     data.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "#     data['Change+'] = list((data['Change'] > 0)[1 : len(data)].astype(int)) + [0]\n",
    "    \n",
    "#     draw_pictures(data, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pDV7QIFsY96O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3106,
     "status": "ok",
     "timestamp": 1653300464826,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "pDV7QIFsY96O",
    "outputId": "90b74d90-7564-4d0b-db72-2509a6a0ab30"
   },
   "outputs": [],
   "source": [
    "# from pykrx import stock\n",
    "\n",
    "# df = stock.get_market_cap_by_ticker(\"20210105\")\n",
    "\n",
    "# company_list = df.index[130 : 140]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "im-n4QSe-ZM-",
   "metadata": {
    "id": "im-n4QSe-ZM-"
   },
   "source": [
    "# 새 섹션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2424c6",
   "metadata": {
    "id": "ac2424c6"
   },
   "source": [
    "### ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec278c06",
   "metadata": {
    "executionInfo": {
     "elapsed": 94927,
     "status": "ok",
     "timestamp": 1653306007156,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "ec278c06"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# paths = glob.glob('./datasets/*.png')\n",
    "# paths = glob.glob('drive/MyDrive/datasets/datasets/*.png')\n",
    "\n",
    "# paths = np.random.permutation(paths)\n",
    "\n",
    "# label = np.array([path[i].split('/')[2] for i in range(len(path))])\n",
    "# print(train.shape, label.shape)\n",
    "# train[1].shape\n",
    "# np.array(plt.imread(paths[i])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e289426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7950741",
   "metadata": {
    "executionInfo": {
     "elapsed": 6416,
     "status": "ok",
     "timestamp": 1653306036386,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "f7950741"
   },
   "outputs": [],
   "source": [
    "# def function():\n",
    "#     global variable\n",
    "#     paths = glob.glob('datasets/datasets/*.png')\n",
    "#     try:\n",
    "#         train = np.array([cv2.imread(paths[i]) for i in range(variable - 10, variable)])\n",
    "#         print(len(train))\n",
    "#     except:\n",
    "#         train = np.array([cv2.imread(paths[i]) for i in range(variable, len(paths))])\n",
    "#     y = []\n",
    "#     for i in range(variable - 10, variable):\n",
    "#         if paths[i][-7] == '1':\n",
    "#             y.append(1)\n",
    "#         elif paths[i][-7] == '0':\n",
    "#             y.append(0)\n",
    "#     y_train = keras.utils.to_categorical(y, 2)\n",
    "#     print(len(y_train))\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(train, y_train, test_size = .2, random_state = 42)\n",
    "#     variable += 10\n",
    "#     return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b22213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "# trans = transforms.Compose([transforms.Resize((100,100)), \n",
    "#                             transforms.ToTensor()])   # transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)\n",
    "\n",
    "# trainset = torchvision.datasets.ImageFolder(root = 'datasets', \n",
    "# \t\t\t\t\ttransform = trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d58029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92f6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # path = 'datasets/datasets'\n",
    "\n",
    "# new_path = 'dataset2/0'\n",
    "\n",
    "# paths = glob.glob('dataset1/datasets1/*.png')\n",
    "\n",
    "# # move\n",
    "# for file in paths:\n",
    "#     if '_0.0' in file:\n",
    "#         shutil.move(file, new_path + '''/''' + file[19:])\n",
    "#         print('{} has been moved to new folder!'.format(file))\n",
    "# print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08eaa52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = glob.glob('datasets/0/*.png')\n",
    "# new_path = 'dataset3/0'\n",
    "# count = 0\n",
    "\n",
    "# for file in paths:\n",
    "#     shutil.move(file, new_path + '/' + file[19:])\n",
    "#     count += 1\n",
    "#     if count == 10000:\n",
    "#         break\n",
    "        \n",
    "# paths = glob.glob('datasets/1/*.png')\n",
    "# new_path = 'dataset3/1'\n",
    "# count = 0\n",
    "\n",
    "# for file in paths:\n",
    "#     shutil.move(file, new_path + '/' + file[19:])\n",
    "#     count += 1\n",
    "#     if count == 10000:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac63b993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46088 files belonging to 2 classes.\n",
      "Using 13827 files for training.\n",
      "Found 46088 files belonging to 2 classes.\n",
      "Using 13826 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# train_labels = y\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory (\n",
    "  'datasets',\n",
    "  label_mode='categorical',\n",
    "  labels = \"inferred\",\n",
    "  shuffle=True,\n",
    "  seed=124,\n",
    "  image_size=(150, 150),\n",
    "  batch_size=32,\n",
    "  subset=\"training\",\n",
    "  validation_split=0.7)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory (\n",
    "  'datasets',\n",
    "  label_mode='categorical',\n",
    "  labels = \"inferred\",\n",
    "  shuffle=True,\n",
    "  seed=124,\n",
    "  image_size=(150, 150),\n",
    "  batch_size=32,\n",
    "  subset=\"validation\",\n",
    "  validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae09aa92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5514,
     "status": "ok",
     "timestamp": 1653306113999,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "ae09aa92",
    "outputId": "74fd7e22-4d7d-4d14-9f88-246b6f7f35a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 22, 22, 48)        13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 11, 11, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 9, 9, 64)          27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 96)          55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 1, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               12416     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 110,546\n",
      "Trainable params: 110,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(50, 50, 3)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(48, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(96, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='sigmoid'))  # 수정 필요\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#               optimizer=keras.optimizers.Adam(), \n",
    "#               metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e4c8442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 148, 148, 48)      1344      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 74, 74, 48)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 262848)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               33644672  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 33,646,274\n",
      "Trainable params: 33,646,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(48, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(48, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='sigmoid'))  # 수정 필요\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=keras.optimizers.Adam(), \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6023ccab",
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1653306119417,
     "user": {
      "displayName": "최선빈",
      "userId": "10702276653678963302"
     },
     "user_tz": -540
    },
    "id": "6023ccab",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "433/433 [==============================] - 70s 159ms/step - loss: 0.6956 - accuracy: 0.5052 - val_loss: 0.6935 - val_accuracy: 0.4873\n",
      "Epoch 2/10\n",
      "433/433 [==============================] - 69s 159ms/step - loss: 0.6943 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.4873\n",
      "Epoch 3/10\n",
      "268/433 [=================>............] - ETA: 18s - loss: 0.6940 - accuracy: 0.5098"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-58da6c75953c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/GPU:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     model.fit(train_ds,\n\u001b[0m\u001b[0;32m      9\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m               epochs=10)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \"\"\"\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    513\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \"\"\"\n\u001b[0;32m   1093\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# batch_size = 100\n",
    "# epochs = 1\n",
    "\n",
    "# trainset\n",
    "\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model.fit(train_ds,\n",
    "          validation_data=test_ds,\n",
    "              epochs=10)\n",
    "\n",
    "    \n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce634179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2808 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds2 = tf.keras.preprocessing.image_dataset_from_directory (\n",
    "  'dataset4',\n",
    "  label_mode='categorical',\n",
    "  labels = \"inferred\",\n",
    "  shuffle=True,\n",
    "  seed=124,\n",
    "  image_size=(50, 50),\n",
    "  batch_size=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e86531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    a = model.predict(train_ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd2a8caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,   1],\n",
       "       [559,   8]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array([])\n",
    "labels =  np.array([])\n",
    "for x, y in train_ds2:\n",
    "    predictions = np.concatenate([predictions, model.predict_classes(x)])\n",
    "    labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n",
    "\n",
    "tf.math.confusion_matrix(labels=labels, predictions=predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f0e9d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 77ms/step - loss: 0.6822 - accuracy: 0.5645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6821510195732117, 0.5644586682319641]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb595620",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-273ce4288ad0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_ds2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "train_ds2.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4201d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14102 files belonging to 2 classes.\n",
      "Using 11282 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds2 = tf.keras.preprocessing.image_dataset_from_directory (\n",
    "  'dataset1',\n",
    "  label_mode='categorical',\n",
    "  labels = \"inferred\",\n",
    "  shuffle=True,\n",
    "  seed=124,\n",
    "  image_size=(50, 50),\n",
    "  batch_size=100,\n",
    "  subset=\"training\",\n",
    "  validation_split=0.2)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    a = model.predict(train_ds2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "348faf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 34ms/step - loss: 0.7883 - accuracy: 0.1765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7882511019706726, 0.1764705926179886]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14866c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/cnn_final_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/cnn_final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086016b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DB_GAPS_STRATEGY_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
