{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44a5f886",
   "metadata": {},
   "source": [
    "# Library import\n",
    "\n",
    "### pytorch로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "df = pd.read_csv('preprocessing.csv')\n",
    "del df['Unnamed: 0']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = df[['credit']].copy()\n",
    "train = df.drop(['credit'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430093b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test data split\n",
    "np.random.seed(42)\n",
    "if \"Set\" not in train.columns:\n",
    "        train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "\n",
    "train_indices = train[train.Set==\"train\"].index\n",
    "valid_indices = train[train.Set==\"valid\"].index\n",
    "test_indices = train[train.Set==\"test\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70cd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding train set and test set\n",
    "nunique = train.nunique()\n",
    "types = train.dtypes\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in train.columns:\n",
    "    if types[col] == 'object' or nunique[col] < 200:\n",
    "        print(col, train[col].nunique())\n",
    "        l_enc = LabelEncoder()\n",
    "        train[col] = train[col].fillna(\"VV_likely\")\n",
    "        train[col] = l_enc.fit_transform(train[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        train.fillna(train.loc[train_indices, col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat = ['Set', 'credit'] # Let's not use splitting sets and sig_id\n",
    "\n",
    "features = [ col for col in train.columns if col not in unused_feat] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9500f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features].values[train_indices]\n",
    "y_train = train_targets.values[train_indices]\n",
    "\n",
    "X_valid = train[features].values[valid_indices]\n",
    "y_valid = train_targets.values[valid_indices]\n",
    "\n",
    "X_test = train[features].values[test_indices]\n",
    "y_test = train_targets.values[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0dda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabnet - multi classifier - clf 변수에 저장\n",
    "clf = TabNetMultiTaskClassifier(n_steps=1,\n",
    "                                cat_idxs=cat_idxs,\n",
    "                                cat_dims=cat_dims,\n",
    "                                cat_emb_dim=1, # embedding dimension\n",
    "                                optimizer_fn=torch.optim.Adam, #Adam-optimizer\n",
    "                                optimizer_params=dict(lr=2e-2), # learning rate\n",
    "                                scheduler_params={\"step_size\":50, # step마다 learning rate에 gamma 곱해서 조절.\n",
    "                                                  \"gamma\":0.9},\n",
    "                                scheduler_fn=torch.optim.lr_scheduler.StepLR, # learning rate scheduler\n",
    "                                mask_type='entmax' #softmax/sparsemax 함수의 일반화 함수,\n",
    "                                lambda_sparse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26761d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "max_epochs = 100\n",
    "clf.fit(X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['accuracy','logloss'],\n",
    "        max_epochs=max_epochs , patience=20,\n",
    "        batch_size=1024, virtual_batch_size=128,\n",
    "        num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a50fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "# Accuracy graph\n",
    "acc = clf.history['train_accuracy']\n",
    "val_acc = clf.history['valid_accuracy']\n",
    "\n",
    "x_len = np.arange(len(acc))\n",
    "\n",
    "plt.plot(x_len, acc, marker='.', c='blue', label=\"Train-set Acc.\")\n",
    "plt.plot(x_len, val_acc, marker='.', c='red', label=\"Validation-set Acc.\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Loss graph\n",
    "loss = clf.history['train_logloss']\n",
    "val_loss = clf.history['valid_logloss']\n",
    "\n",
    "x_len = np.arange(len(acc))\n",
    "\n",
    "plt.plot(x_len, loss, marker='.', c='blue', label=\"Train-set loss.\")\n",
    "plt.plot(x_len, val_loss, marker='.', c='red', label=\"Validation-set loss.\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Cross-entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4215a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance 확인\n",
    "preds_valid = clf.predict_proba(X_valid) \n",
    "preds = clf.predict_proba(X_test)\n",
    "clf.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
